---
title: "_Лабораторна робота №3._ Побудова моделі парної регресії"
author: "[Зайкін А. В.](https://www.linkedin.com/in/zaykinandrew/), `r format(Sys.time(), '%Y')`"
date: "`r Sys.Date()`"
output:
  html_notebook:
    toc: yes
    toc_float: true
    highlight: tango
    code-fold: true
    code-line-numbers: true
    code-tools: true
    code-copy: true
fontsize: 12pt
lang: ukr
header-includes:
 \usepackage[T2A]{fontenc}
 \usepackage[utf8]{inputenc}
 \usepackage[russian]{babel}
editor_options: 
  chunk_output_type: console
---

```{r warning=FALSE, message=FALSE, include=FALSE, paged.print=FALSE}
packages <- c("rio", "magrittr", "ggplot2", "dplyr", "corrplot", "funModeling", "knitr", "factoextra", "FactoMineR", "randomForest")
lapply(packages, library, character.only = TRUE, quietly = TRUE)
```

# Короткі теоретичні відомості

### Що таке лінійна регресія?
Лінійна регресія (англ. Linear Regression) - це метод статистичного моделювання, який використовується для аналізу залежності між двома змінними: залежною та незалежною. Залежна змінна - це та, яка залежить від іншої змінної, а незалежна змінна - це та, яка впливає на залежнuу змінну.

# Постановка задачі

### Мета роботи:

1. Засвоєння принципів, знайомство з інструментами та набуття навичок побудови моделі лiнiйної регресії засобами мови програмування R та функцiй `lm()`, `summary()`, `plot()`, `abline()`.
2. Побудова моделі лiнiйної регресії залежностi ваги від зросту жінок засобами мови програмування R та функцiй `lm()`, `summary()`, `plot()`, `abline()`.

# Виконання завдання

З виконання минулої лабораторної роботи ми дiзнались:

* Данi не є однорідними (не гомогенні), а це означає, що необхiдний аналіз для кожної групи окремо.
* Данi симметричнi та мають нормальний розподiл. Тому для побудови моделi ми можемо використовувати модель лiнiйної регресії на основi МНК (методу найменших квадратів). 

Для початку iмпортуємо дані та вiдфільтруємо їх тільки для жінок.

```{r warning=FALSE}
people <- import("data/hw.xlsx")

women <- people %>%
  filter(`Стать` == "Woman")
```

Тепер побудуємо графік регресії залежності ваги від зросту жінок та модель лінійної регресії.

```{r warning=FALSE}

plot(women$`Зріст, см`, women$`Вага, кг`,
     main = "Лінія регресії",
     xlab = "Зріст, см", 
     ylab = "Вага, кг",
     )
lm <- lm(`Вага, кг` ~ `Зріст, см`, data = women)
abline(lm, col = "red")
```

З графіку бачимо, що лiнiя регресiї адекватно відображає залежність ваги від зросту жінок. Виведемо статистику моделі.

```{r warning=FALSE}
summary(lm)
```

Проаналiзувавши статистику моделi i графiк, можемо зробити такі висновки:

- Регресiйне рiвняння має вигляд: `Вага, кг = -27.5600 + 0.5414 * Зріст, см`.
- Коефiєнт зросту статистично значимий (p-value < 0.05), що означає, що зв'язок між зростом та вагою не є випадковим.
- Вiльний член не значимий (p-value > 0.05), при зростi 0 см не має практичного сенсу.
- Графiк регресiї має два викиди, які впливають на модель.
- Модель не адекватна, оскiльки коефiєнт детермiнацii R-squared = 0.1146, що означає, що лише 11.46% змiнностi ваги пояснюється зростом.
- Але загалом модель статистично значима, оскiльки загальний p-value < 0.05.

З висновкiв виходить, що для того щоб покращити модель, потрiбно позбутися вiльного члена та вiдфільтрувати викиди. Вiдразу виведемо нову статистику моделі.

```{r warning=FALSE}
women <- women %>%
  filter(`Вага, кг` < 100)

lm <- lm(`Вага, кг` ~ `Зріст, см` - 1, data = women)
summary(lm)
```

Тепер модель стала бiльш адекватною, оскiльки R-squared = 0.9818.
Регресiйне рiвняння має вигляд: `Вага, кг = 0.3684 * Зріст, см`. Модель лiнiйної регресiї цiлком пiдходить для аналiзу залежностi ваги від зросту жінок. Виведемо дiагностичні графіки моделі, щоб краще зрозуміти, як модель поводить себе.

```{r warning=FALSE}
plot(lm)
```

З дiагностичних графiкiв бачимо, що залежнiсть ваги від зросту не можна назвати повнiстю лiнiйною, дисперсiя залишкiв не є сталою, а також є викиди. Але така природа є характерною для даних зросту та ваги людей. Кожна людина може мати будь який зрiст та вагу, тому така модель є адекватною. Але якщо потрiбно покращити модель, то можна використовувати моделi на основi машинного навчання, таких як дерева рiшень, навчання з пiдказками тощо. Але це вже тема для наступної лабораторної роботи.

Побудуємо графiк регресiї з довiрчими iнтервалами.

```{r warning=FALSE, message=FALSE}
ggplot(women, aes(x = women$`Зріст, см` - 1, y = women$`Вага, кг`)) +
	labs(title = "Залежність ваги від зросту жінок",
			 subtitle = "Лiнiйна регресiя з 97% довiрчого інтервалу",
       x = "Зріст, см",
       y = "Вага, кг") +
	geom_point() +
	stat_smooth(method = "lm", se = TRUE, level = 0.89)
```

Ciра зона на графіку показує надiйну зону регресії – нижню та верхню 97%-у межу прогнозу для середнього значення ваги. Обчислюється вона так:

```{r warning=FALSE, message=FALSE}
heightNumber <- data.frame(`Зріст, см` = c(160, 170, 180), check.names = FALSE)
pre <- predict(lm, heightNumber, interval = "confidence")
knitr::kable(cbind(heightNumber, pre), caption = "Predicted height")
```

Наприклад, якщо зрiст дорiвнює 160 см, то середнє значення ваги буде в межах вiд 57.33 кг до 60.56 кг з 97% довiрчою iмовiрнiстю. Аналогiчно можна обчислити довiрчi iнтервали для будь-якого зросту.

### Висновки

1. Мiж зростом та вагою жінок існує лiнiйна кореляцiя, але вона не є строгою. Це означає, що зростання збiльшує вагу, але не настiльки, щоб можна було сказати, що зростання на 1 см завжди призводить до збiльшення ваги на 0.3684 кг.
2. Моделi машинного навчання можуть покращити модель, але з огляду на природу даних, такі моделi можуть не дати кращого результату.
3. Доцільно збільшення об’єму вибіркових даних хоча б на порядок для перевірки адекватності моделі.

```{r warning=FALSE, message=FALSE}
str(lm)
```







