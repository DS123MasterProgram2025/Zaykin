---
title: "_Лабораторна робота №6._ Побудова ARIMA-моделі часового ряду і прогнозування на її основі"
author: "[Зайкін А. В.](https://www.linkedin.com/in/zaykinandrew/), `r format(Sys.time(), '%Y')`"
date: "`r Sys.Date()`"
output:
  html_notebook:
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: none
    code-line-numbers: true
    code-tools: true
    code-copy: true
fontsize: 18pt
lang: ukr
header-includes:
 \usepackage[T2A]{fontenc}
 \usepackage[utf8]{inputenc}
 \usepackage[russian]{babel}
editor_options: 
  chunk_output_type: console
---

```{css, echo=FALSE}
h1 {
  margin-top: 1.25em;
}

p {
  font-size: 12pt;
  text-align: justify;
  margin: 20px 0 10px;
}
```

# Короткі теоретичні відомості

### Визначення часового ряду

__Визначення.__ Часовий ряд (time series) -- сукупність спостережень будь-якої величини $X$ в різні моменти часу.  
_Приклад_: сумарна кількість проданих товарів по днях, щоденний курс долара, середньодобова температура або вологість у кімнаті тощо.  
Будемо розглядати часовий ряд як вибірку з послідовності $X_t$, де $t \in [1, \; T]$ (іноді $t \in [0, \; T]$).

### Процес середнього ковзного $MA(q)$

__Визначення.__ Стохастичний процес називається процесом середнього ковзного порядка $q$ і позначається як $MA(q)$: $$x_t = \sum_{\tau = 0}^ q \psi_t \cdot \epsilon_{t-\tau} = \epsilon_t + \psi_1 \epsilon_{t-1} + ... + \psi_q \epsilon_{t-q}, \; x_t = X_t - \mu.$$ 

Процесс $MA(q)$ є стаціонарним __завжди.__

_Властивості:_  

1. $E \{ x_t\} =0;$  
2. $V(x_t) = \sigma^2 \sum_{i=0}^q \psi_i^2.$  
3. $Cov(x_t, \; x_{t+\tau}) = 0.$

### Процес авторегресії $AR(p)$

__Визначення.__ Процес, значення якого визначаються лінійною комбінацією скінченної кількості його попередніх значень і додаванням білого шуму, називається _процесом авторегресії (autoregression)_ порядка $p$ і його загальне рівняння має вигляд: $$X_t = \alpha_1 X_{t-1} + \alpha_2 X_{t-2} + ... + \alpha_p X_{t-p} + \epsilon_t,$$  

де $\epsilon_t$ -- білий шум.  

У цих термінах процес, зворотний до $MA(q)$, може бути обозначений як $AR(\infty)$.  
Однак ми не маємо гарантії, що при $\forall$ коефіцієнтів $\alpha_1, \alpha_2,..., \alpha_p$ буде стаціонарним.  
Для того, щоб він був стаціонарним, необхідно, щоби він був представимий у вигляді розкладу Вольда, щоби його можна було перевести в $MA(q)$, який __завжди__ стаціонарний.  

_Властивості стаціонарного $AR(p)$-процесу:_ 

1. _Математичне сподівання процесу_: $E(X_t) = 0.$ 
2. _Автоковаріаційна функція $AR(p)$ процесу_: $\gamma(\tau) = \alpha_1 \gamma(\tau - 1) + ... + \alpha_p \gamma(\tau - p).$

### Процес авторегресії і середнього ковзного $ARMA(p, q)$

__Визначення.__ Стохастичний процес називається _процесом авторегресії і середнього ковзного_ і позначається як $ARMA(p, q)$:

$$X_t = \alpha_1 X_{t-1} + ... + \alpha_p X_{t-p} + \epsilon_{t-1} + ... + \beta_q \epsilon_{t-q}.$$
Можна показати, що стаціонарність ARMA-процесу визначається його AR-частиною, тому умови ті ж самі, що і у AR-процеса: процес ARMA э стаціонарним, якщо корні характеристичного рівняння AR-частини по модулю $< 1$. 

Очевидно, що для $ARMA(p, q):$ $E \{ X_t \} = 0$

### ARIMA-процес (autoregressive integrated moving average)

__Визначення.__ Процес, який отримується з $ARMA(p, q)$ шляхом диференціювання $d$ разів, називається _процесом авторегресії інтегрованого середнього ковзного_ і позначається як $ARIMA(p, d, q)$:

$$(1 - \alpha_1 L - \alpha_2 L^2 - ... - \alpha_p L^p)(1 - L)^d X_t = \epsilon_t + \beta_1 \epsilon_{t-1} + ... + \beta_q \epsilon_{t-q}$$

# Постановка задачі

### Мета роботи:

1. Виконати візуалізацію часових рядів (ЧР) щорічної кількості випадків чоловічого безпліддя в Україні.
2. Перевірити ЧР на стаціонарність і зводити його до стаціонаного у разі його не стаціонарності.
3. Виконати структурну і параметричну ідентифікацію ARIMA-моделі для ЧР.
4. Побудувати прогноз на 2-3 роки вперед на основі побудованої ARIMA-моделі.
5. Висунути гіпотези щодо можливого пояснення саме такої динаміки.

# Виконання завдання

```{r warning=FALSE, message=FALSE, include=FALSE, paged.print=FALSE}
packages <- c("forecast", "tseries", "ggplot2", "readxl")
lapply(packages, library, character.only = TRUE, quietly = TRUE)
```

Зараз данi сортованi по областях, але будемо розглядати данi по Україні в цілому. Для цього ми повинні привести данi до загальної кількості випадків по роках. Виключимо данi по окупованих територіях.

```{r warning=FALSE}
data <- read_excel("data/infertility.xlsx")

# Видалити рядки з областями, які потрібно виключити
exclude_regions <- c("Автономна pеспубліка Крим", "Донецька", "Луганська", "м.Севастополь")
data <- data[!(data[[1]] %in% exclude_regions), ]

# Розрахунок загальної кількості випадків по роках
years <- 1993:2017
totals <- colSums(data[, as.character(years)], na.rm = TRUE)

# Створення dataframe
df <- data.frame(Year = years, Cases = totals)

# Перегляд даних
head(df)
```

Тепер ми можемо виконати візуалізацію часового ряду.

```{r warning=FALSE}
# Створення об'єкта ts (time series)
# start = c(рік початку), frequency = 1 (річні дані)
ts_data <- ts(df$Cases, start = 1993, frequency = 1)


# Візуалізація початкових даних
plot(ts_data, 
     main = "Динаміка чоловічого безпліддя в Україні (1993-2017)",
     xlab = "Рік",
     ylab = "Кількість випадків",
     col = "blue",
     lwd = 2)
grid()
```

На графiку чiтко видно, що ряд нестаціонарний. Тому можемо пропустити перевiрку стаціонарностi через `ADF` та `KPSS` тести. Далi спробуємо звести ряд до стаціонарного шляхом диференціювання.

```{r warning=FALSE}
ts_diff1 <- diff(ts_data, differences = 1)

# Візуалізація диференційованого ряду
plot(ts_diff1,
     main = "Перше диференціювання",
     xlab = "Рік",
     ylab = "Зміна кількості випадків",
     col = "red",
     lwd = 2)
abline(h = 0, lty = 2)

# ADF-тест для диференційованого ряду
adf.test(ts_diff1, alternative = "stationary") %>% print()
```

З аналiзу графiку та ADF-тесту ми бачимо, що ряд залишився нестаціонарним. Видно невеликий тренд i `P-value > 0.05`, тому спробуємо звести його до стаціонарного шляхом другого диференціювання.

```{r warning=FALSE}
# Якщо все ще нестаціонарний, застосувати друге диференціювання
ts_diff2 <- diff(ts_data, differences = 2)

# Візуалізація диференційованого ряду
plot(ts_diff2,
     main = "Друге диференціювання",
     xlab = "Рік",
     ylab = "Зміна кількості випадків",
     col = "green",
     lwd = 2)
abline(h = 0, lty = 2)

# ADF-тест для диференційованого ряду
adf.test(ts_diff2, alternative = "stationary") %>% print()
```

Пiсля другого диференціювання ряд став стаціонарним (`P-value < 0.05`) i це добре видно на графiку.

Тепер ми можемо оцінити автокореляцію ряду. Побудуємо графiки функцiй автокореляцiї (`ACF`) та часткової автокореляцiї (`PACF`).

```{r warning=FALSE}
# ACF (Autocorrelation Function) - визначає q
acf(ts_diff2, 
    main = "Функція автокореляції (ACF)",
    lag.max = 10)

# PACF (Partial Autocorrelation Function) - визначає p
pacf(ts_diff2,
     main = "Часткова автокореляція (PACF)",
     lag.max = 10)
```

На графiках ACF та PACF залишаються видимi значимi викиди. Для того щоб пiдiбрати бiльш адекватну модель проаналiзуємо залишки моделi через їх ACF та PACF. Почнемо з моделi `ARIMA(0, 2, 0)`.

```{r warning=FALSE}
arima_model <- arima(ts_data, order = c(0, 2, 0))
residials_model <- residuals(arima_model)
acf(residials_model, main = "ACF залишків")
pacf(residials_model, main = "PACF залишкiв")
```

Як i на попередньому графiку, залишки мають значимi викиди. Спробуємо привести їх до бiлого шуму. Спочатку спробуємо модель `ARIMA(1, 2, 0)`, бо викид на першому лазi в PACF бiльш помiтний.

```{r warning=FALSE}
arima_model <- arima(ts_data, order = c(1, 2, 0))
residials_model <- residuals(arima_model)
acf(residials_model, main = "ACF залишків")
pacf(residials_model, main = "PACF залишкiв")
```

Тепер часовий ряд залишкiв коливається без видимого тренду. Коефіцієнт на першому лазi в ACF завжди буде рiвний 1, бо це корреляцiя з самим собою. На останок проведемо тести на нормальність та автокореляцію залишків.

```{r warning=FALSE}
# Перевірка залишків на наявність автокореляції
checkresiduals(arima_model)
# Тест на нормальність
shapiro.test(residuals(arima_model))
```

На графiку залишкiв видно, що вони не мають тренду та коливаються навколо нуля. P-value Ljung-Box > 0.05, тому залишки є бiлим шумом. P-value Shapiro-Wilk < 0.05 — залишки не є нормально розподіленими. Але це не критично, тому що ми не використовуємо залишки для прогнозування, а лише для оцінки адекватності моделі.

Щоб впевнитись що ми пiдiбрали правильнi параметри, побудуємо ARIMA-модель за допомогою функцiї `auto.arima()`.

```{r warning=FALSE}
arima_auto_model <- auto.arima(ts_data,
                          seasonal = FALSE,        # немає сезонності (річні дані)
                          stepwise = FALSE,        # перебір всіх моделей
                          approximation = FALSE,   # точні обчислення
                          trace = TRUE)            # виводити процес пошуку
```

Автоматично пiдiбрана модель вiдрiзняється вiд моделi `ARIMA(1, 2, 0)`. Для перевiрки адекватностi оцінимо точність обох моделей, беручи останні 3 роки як тестові дані для побудови прогнозу i виводу метрик точностей.

Спочатку розділимо данi на тренувальну та тестову вибірки i побудуємо прогнози для тренувальних даних.

```{r warning=FALSE}
# Розділення даних на тренувальну та тестову вибірки
train_size <- length(ts_data) - 3  # Останні 3 роки для тесту
train_data <- window(ts_data, end = c(2014, 1))
test_data <- window(ts_data, start = c(2015, 1))

# Побудова моделі на тренувальних даних
model_train <- arima(train_data, order = c(1, 2, 0))
auto_model_train <- arima(train_data, order = c(1, 2, 1))

# Прогноз на 3 роки
forecast_test <- forecast(model_train, h = 3)
forecast_auto_test <- forecast(auto_model_train, h = 3)
# Порівняння прогнозу з фактичними даними
accuracy_result <- accuracy(forecast_test, test_data)
accuracy_auto_result <- accuracy(forecast_auto_test, test_data)
```

Тепер виведемо метрики точностей та візуалізуємо прогнози.

```{r warning=FALSE}
print(accuracy_result)
print(accuracy_auto_result)

# Візуалізація порівняння
plot(forecast_test, 
     main = "Порівняння прогнозу з фактичними даними")
lines(test_data, col = "red", lwd = 2)
legend("topleft",
       legend = c("Прогноз", "Фактичні дані"),
       col = c("blue", "red"),
       lty = 1,
       lwd = 2)

plot(forecast_auto_test, 
     main = "Порівняння автоматичного прогнозу з фактичними даними")
lines(test_data, col = "red", lwd = 2)
legend("topleft",
       legend = c("Прогноз", "Фактичні дані"),
       col = c("blue", "red"),
       lty = 1,
       lwd = 2)
```

Модель `ARIMA(1, 2, 0)` має більш високу точність, ніж автоматично пiдiбрана модель. Це можна побачити як i на графiку порівняння прогнозу з фактичними даними, так i на метриках точностей:

* Меншi коефіцієнти помилок (`RMSE`, `MAE`, `MAPE`)
* Менший коефіцієнти зсуву (`ME`)
* Менший загальний показник (`U < 0.5`)

Тепер побудуємо прогноз на 3 роки вперед для моделi `ARIMA(1, 2, 0)`.

```{r warning=FALSE}
# Прогноз на h періодів вперед (h = 2-3 роки)
forecast_result <- forecast(arima_model, h = 3)

# Додатковий графік з ggplot2
autoplot(forecast_result) +
  labs(title = "ARIMA прогноз: Чоловіче безпліддя в Україні",
       x = "Рік",
       y = "Кількість випадків") +
  theme_minimal()
```

Модель передбачає продовження восходящого тренду. Очікуване значення до 2020 року: ~19500-27500 випадків. Довірчий інтервал розширюється з часом — відображає зростаючу невизначеність прогнозу.

В завершенні виведемо параметри моделi `ARIMA(1, 2, 0)` та запишему загальне рівняння моделі.

```{r warning=FALSE}

# Витягуємо коефіцієнти моделі
coefs <- coef(arima_model)
intercept <- coefs["intercept"]
ar1 <- coefs["ar1"]
```

Загальне рівняння моделі ARIMA(1, 2, 0):

$$
\nabla^2 Y_t = `r round(coef(arima_model)["ar1"], 4)` \cdot \nabla^2 Y_{t-1} + \varepsilon_t
$$

# Висновки

1. В серединi 00-x рокiв відбувся різкий стрибок у популярності та доступності кредитів. У цей час вже iснували приватнi лiкарнi, якi надавали послуги репродуктивнiй медицинi. Це призвело до того, що більше чоловіків стали отримувати доступ до послуг перевiрки на безпліддя. Фактично не можна казати, що за цей перiод часу побiльшало кількість випадків безпліддя. Але виявлення такого дiагнозу стало легше, тому ми бачимо рiзке зростання кількостi випадків безпліддя.
2. Модель `ARIMA(1, 2, 0)` має більш високу точність, ніж автоматично пiдiбрана модель. Цей приклад змушує бiльш ретельно пiдбирати параметри моделi та враховувати їхню адекватнiсть.